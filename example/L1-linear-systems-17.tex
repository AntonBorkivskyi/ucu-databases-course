\documentclass%[draft]%
[handout]%
{beamer}
%%%%%%%%%%%%%%%%%
%\usepackage[absolute,overlay]{textpos}
%\usepackage{tikz}
%\usetikzlibrary{shadows}
%%%%%%%%%%%%%%%%%%
\usepackage{bm}

\usepackage{pdfsync}

\usepackage[normalem]{ulem}

\mode<presentation>
{
  %\usetheme{Warsaw}
  %\usetheme{Madrid}
  \usetheme{Frankfurt}
  % or ...


  \setbeamercovered{transparent}
  % or whatever (possibly just delete it)
}


\usepackage[english]{babel}
% or whatever

\usepackage[latin1]{inputenc}
% or whatever

\usepackage{times}
\usepackage[T1]{fontenc}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.

%%%%%%%%%% commands %%%%%%%%%%

%\textheight=185truemm \voffset=-20truemm \textwidth=240mm

%\pagestyle{plain}
%\newcounter{null}

%%%%%%%%%%%%%%  Definitions %%%%%%%%%%%%%%

\newtheorem{question}{Question}

%%%%%%%%%%%%%%%   matrix extension  %%%%%%%%
\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
  \hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{#1}}
\makeatother
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\one}{\hbox{\rm 1\kern-.27em I}}%
\newcommand{\rank}{\operatorname{rank}}

%\newcommand\PP{\stackrel{\sfP}{\rightarrow}}
%\newcommand\LL{\stackrel{{\mathcal L}}{\rightarrow}}

\newcommand\purple[1]{{\color{purple} #1}}
\newcommand\blue[1]{{\color{blue} #1}}

\newcommand{\re}{\mathrm{e}}
\newcommand{\ri}{\mathrm{i}}

\newcommand{\ov}{\overline}
\newcommand{\wt}{\widetilde}

\newcommand\la{\lambda}
\newcommand\bla{\bm{\lambda}}

\newcommand{\bN}{{\mathbb N}}
\newcommand{\bR}{{\mathbb R}}
\newcommand{\bZ}{{\mathbb Z}}

\newcommand{\bb}{{\mathbf b}}
\newcommand{\be}{{\mathbf e}}
\newcommand{\bg}{{\mathbf g}}
\newcommand{\bp}{{\mathbf p}}
\newcommand{\bv}{{\mathbf v}}
\newcommand{\bw}{{\mathbf w}}
\newcommand{\bx}{{\mathbf x}}
\newcommand{\by}{{\mathbf y}}
\newcommand{\bz}{{\mathbf z}}


\newcommand{\cB}{{\mathcal B}}
\newcommand{\cF}{{\mathcal F}}
\newcommand{\cG}{{\mathcal G}}
\newcommand{\cN}{{\mathcal N}}
\newcommand{\cP}{{\mathcal P}}
\newcommand{\cT}{{\mathcal T}}

\newcommand{\Cor}{{\mathsf{Cor}}}
\newcommand{\Cov}{{\mathsf{Cov}}}
\newcommand{\sfD}{{\mathsf{Var}}}
\newcommand{\sfE}{{\mathsf E}}
\newcommand{\sfP}{{\mathsf P}}

\newcommand\rv{{\sf r\,\!v}}
\newcommand\pdf{{\sf pdf}}
%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\title{Linear Algebra}

\subtitle{Lecture Notes} % (optional)

\author[R.~Hryniv] % (optional, use only with lots of authors)
{Rostyslav Hryniv}
% - Use the \inst{?} command only if the authors have different
%   affiliation.

\institute[IAPMM]%[Universities of Somewhere and Elsewhere] % (optional, but mostly needed)
{
  %
  Ukrainian Catholic University\\
  Computer Science Programme
}
% - Use the \inst command only if there are several affiliations.
% - Keep it simple, no one is interested in your street address.

\date%[]%[Short Occasion] % (optional)
{$3^{\mathrm{rd}}$ term\\ Autumn 2017}


\titlegraphic{\includegraphics[height=3cm]{UCU-Apps.png}}

\subject{Talks}
% This is only inserted into the PDF information catalog. Can be left
% out.



% If you have a file called "university-logo-filename.xxx", where xxx
% is a graphic format that can be processed by latex or pdflatex,
% resp., then you can add a logo as follows:

% \pgfdeclareimage[height=0.5cm]{university-logo}{university-logo-filename}
% \logo{\pgfuseimage{university-logo}}



% Delete this, if you do not want the table of contents to pop up at
% the beginning of each subsection:
\AtBeginSubsection[]
{
  \begin{frame}<beamer>{Outline}
    \tableofcontents[currentsection,currentsubsection]
  \end{frame}
}


% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command:

\beamerdefaultoverlayspecification{<+->}

%\includeonlyframes{linear,linear-example1,linear-example2,linear-example3}
%\includeonlyframes{dim2,possibilities2,solving-2}
%\includeonlyframes{dim3,possibilities3,solving-3}
%\includeonlyframes{large-n,matrix-formulation,augmented-matrix}
%\includeonlyframes{elem-row,echelon,pivot-free,free,reduced-echelon}
%\includeonlyframes{homogeneous,nonhomogeneous,existence,uniqueness}
%\includeonlyframes{hom-prop}
%\includeonlyframes{hom-utility}
%\includeonlyframes{card-vs-ord}
%\includeonlyframes{homothetic-char}
%\includeonlyframes{conv-def}
%\includeonlyframes{conv-1dim}
%\includeonlyframes{conv-calc-crit}
%\includeonlyframes{quasiconcave,quasiconcave1}


%\nofiles
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\begin{frame}
\thispagestyle{empty}
  \titlepage
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}

\begin{center}
	Lecture~1. Systems of linear equations
\end{center}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[label=outline]{Outline}
\setcounter{tocdepth}{2}
  \tableofcontents%[pausesections]
% You might wish to add the option [pausesections]
\end{frame}


\section{Systems of linear equations}


\subsection{Examples. Solutions. Substitution and elimination}

\begin{frame}[label=linear]{Systems of linear equations}

\vspace*{-8pt}

\begin{block}{}
  Many applied models postulate linear dependence on some \alert{variables} (e.g., economic factors) $\alert{x},\alert{y},\alert{z},\dots$:\\[-15pt]
  \[
        \blue{a}\alert{x} + \blue{b} \alert{y} + \blue{c} \alert{z} + \dots = \blue{\alpha}
  \]\\[-5pt]
  Here $\blue{a}, \blue{b}, \blue{c}, \dots, \blue{\alpha}$ are given \blue{numbers}, or \blue{scalars}%
%  and $\alert{x},\alert{y},\alert{z},\dots$ are (\alert{unknowns})
  \begin{footnote}
     {Can be real ($\mathbb{R}$), complex ($\mathbb{C}$), quaternionic~($\mathbb{H}$), binary ($\mathbb{Z}_2$), in  $\mathbb{Z}_p$ \dots}
   \end{footnote}
\end{block}

\vspace{-6pt}

\begin{itemize}
  \item For many ($n$) parameters, use notations~$\alert{x_1},\alert{x_2},\dots,\alert{x_n}$
  \item %If there are several relations, get \\
      \alert{system of linear equations}, or \alert{linear system} \\[-10pt]
\begin{equation}\label{eq:lin-sys} \begin{matrix}
    a_{11}\alert{x_1} + a_{12}\alert{x_2} + \cdots + a_{1n} \alert{x_n} \hspace{-8pt}&= \ b_1\\
    a_{21}\alert{x_1} + a_{22}\alert{x_2} + \cdots + a_{2n} \alert{x_n} \hspace{-8pt}&= \ b_2\\
    \hdotsfor{2} \\
    a_{m1}\alert{x_1} + a_{m2}\alert{x_2} + \cdots + a_{mn} \alert{x_n} \hspace{-8pt}&= \,b_m
   \end{matrix}
\end{equation}
\item usually $x_1,\dots,x_n$ are \alert{unknown}; to be determined from~\eqref{eq:lin-sys}
\end{itemize}

\vspace*{-8pt}

\begin{definition}[Solution to a system]
A sequence $(x_1,x_2,\dots,x_n)$ of numbers turning each equation in~\eqref{eq:lin-sys} into equality is a \alert{solution} of the linear system~\eqref{eq:lin-sys}.
\end{definition}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[label=linear-example1]{Lavrentief model (Nobel prize in economics in 1973):}
\vspace*{-5pt}
\begin{itemize}
    \item in 1949, divided the American economy in $N=500$ sectors % (coal industry, automotive, communications, \dots)
    \item analyzed distribution of the outcomes
    \item got the $N\times N$ linear system ($N\le 32$ feasible in 1949)
%    \item the available computers could only handle $N\le 32$
%    \item Leontief got the Nobel prize in economy in 1973
\end{itemize}
\vspace*{-5pt}
\begin{block}
{Production matrix for a simple economy model (N=3):}
\begin{center}\begin{tabular}{|l|l|l|l|}
 \hline
 &\multicolumn{3}{c}{Income Required per Dollar Output in} \vline\\
 \cline{2-4}
 &  Manufacturing & Agriculture &Utilities \hphantom{www} \\
 \hline
Manufacturing & \$ 0.50 & \$ 0.10 & \$ 0.10 \\
Agriculture & \$ 0.20 &\$ 0.50 &\$ 0.30 \\
Utilities &\$ 0.10 &\$ 0.30 &\$ 0.40 \\
\hline
\end{tabular}\end{center}
$\alert{x_1},\alert{x_2},\alert{x_3}$: produced output; $d_1,d_2,d_3$: demand\\[-20pt]
\begin{align*}
 x_1 - (0.5x_1 + 0.1x_2 + 0.1x_3) &= d_1\\
  x_2 - (0.2x_1 + 0.5x_2 + 0.3x_3) &= d_2\\
  x_3 - (0.1x_1 + 0.3x_2 + 0.4x_3) &= d_3
\end{align*}
\end{block}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[label=linear-example2]{Balancing chemical reactions}
Combustion of propane produces carbon dioxide  and water:
\begin{block}{}
\begin{tabular}{ccccccc}
  $C_3H_8$ & + & $O_2$ &$\rightarrow$& $CO_2$ & + & $H_2O$\\
  propane && oxygen &&carbon dioxide&&water
\end{tabular}
\end{block}
To balance the equation, take \alert{$x$} molecules of propane, \alert{$y$} of oxygen, \alert{$z$} of carbon dioxide and \alert{$w$} of water; now equate the number of atoms on both sides to get
\begin{alignat*}{2}
  3x &= z &\qquad &\text{(Carbon)}\\
  8x &= 2w &\qquad &\text{(Hydrogen)}\\
  2y &= 2z+w&\qquad &\text{(Oxygen)}
\end{alignat*}
Many solutions, e.g. $x=1$, $y=5$, $z=3$, and $w=4$:
\[
    C_3H_8 + \alert{5}O_2 = \alert{3}CO_2 + \alert{4}H_2O
\]
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[label=linear-example3]{Polynomial approximation}

\begin{theorem}
  For any $n$ given pairs $(x_1,y_1)$, \dots, $(x_n,y_n)$ with pairwise distinct~$x_k$ there exists a unique polynomial p(x) of degree at most $n-1$ such that $p(x_k) = y_k$ for every $k=1,\dots,n$.
\end{theorem}

Search for $p$ of the form
\[
    p(x) = a_0 + a_1 x + a_2 x^2 + \dots + a_{n-1}x^{n-1};
\]
then we get
\[
\begin{matrix}
    a_0 + a_1 x_1+ a_2 x_1^2 + \dots + a_{n-1}x_1^{n-1} &= y_1\\
    a_0 + a_1 x_2+ a_2 x_2^2 + \dots + a_{n-1}x_2^{n-1} &= y_2\\
    \hdotsfor{2}\\
    a_0 + a_1 x_n+ a_2 x_n^2 + \dots + a_{n-1}x_n^{n-1} &= y_n
\end{matrix}
\]

This is a linear system for the coefficients $\alert{a_0}, \alert{a_1}, \dots, \alert{a_{n-1}}$!
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Solutions in dimension~$2$}

\begin{frame}[label=dim2]{Linear systems in dimension~$2$:}

\vspace*{-8pt}

\begin{block}{Lines in $\bR^2$}
\begin{itemize}
  \item  In the $xy$-plane, equation $y = kx + m$ gives a line through $(0,m)$ with the slope $k$
  \item  If $|a|+|b|>0$, then\\[-10pt]
\[
    ax + by = c
\]
describes the line with slope $k=-a/b$ through $(0,c/b)$ if $b\ne0$,  or the line $x\equiv c/a$ otherwise
  \item this line is orthogonal to the vector $(a,b)$
\end{itemize}
\end{block}

\vspace*{-5pt}

\begin{center}\includegraphics[width=4cm]{line.png}
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[label=possibilities2]{Possible situations:}

%\vspace*{-10pt}

\begin{center}\includegraphics[width=11cm]{lines-2.png}
\end{center}

\begin{enumerate}
  \item Lines coincide \hspace{1pt}$\implies$ infinitely many solutions
  \item Lines parallel \hspace{3pt} $\implies$ no solutions
  \item Lines intersect $\implies$ single solution
\end{enumerate}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[label=solving-2]{Solving linear systems in dimension $2$:}

\begin{block}{By substitution:}
    \[ \begin{matrix}[rrr]
        2x &+ \hphantom{2}y &= 3 \\
        3x &- 2y &= 8
    \end{matrix}
    \quad \implies \quad
    \begin{matrix}[l]
        \blue{x = \tfrac12(3-y)} \qquad\qquad \alert{\times 3} \\
        \blue{\tfrac{\alert{3}}2(3-y)} - 2y\ = 8
     \end{matrix}
    \]
    From the second equation $y=-1$ and then the first gives $x=2$
\end{block}

\begin{block}{By elimination:}

\vspace*{-10pt}

    \begin{alignat*}{3}
        &\begin{matrix}[rrrr]
        2x &+ \hphantom{2}y &= \hphantom{-}3 &\\
        3x &- 2y &= \hphantom{-}8 & \quad \alert{-\tfrac32\times(1)}
        \end{matrix}
    &\quad &\implies &\quad
        &\begin{matrix}[rrr]
        2x &+ \hphantom{2}y &= \hphantom{-}3\\
            & -\tfrac72y &= \hphantom{-}\tfrac72
        \end{matrix}
    \quad \implies
    \\  \\
    &\begin{matrix}[rrrr]
        2x &+ \hphantom{2}y &= \hphantom{-}3 & \quad \alert{ - 1\times(2)}\\
            & y &= -1 &
        \end{matrix}
     &\quad &\implies &\quad
     &\begin{matrix}[rrr]
        2x &   &= \hphantom{-}4\\
           &\hphantom{-2} y &= -1
      \end{matrix}
  \end{alignat*}
\end{block}

The two methods are only formally different

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Solutions in dimension~$3$}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[label=dim3]{Linear systems in dimension~$3$:}
\vspace*{-7pt}
  \begin{block}{Planes in $\bR^3$}
  \begin{minipage}[b]{6cm}
  If $|a|+|b|+|c|>0$, then the equation
  \[
      ax+ by + cz = d
  \]
  describes in the $xyz$-space the plane orthogonal to the direction vector $(a,b,c)$
  \end{minipage} \qquad
    \includegraphics[width=3.5cm]{plane.png}
  \end{block}

  \vspace*{-5pt}

  \begin{block}{Systems in $\bR^3$:}
  \[
    \begin{matrix}
      a_{11}x_1 + a_{12}x_2 + a_{13}x_3 &=b_1\\
      a_{21}x_1 + a_{22}x_2 + a_{23}x_3 &=b_2\\
      a_{31}x_1 + a_{32}x_2 + a_{33}x_3 &=b_3
    \end{matrix}
  \]
  describes the common (intersection) points of three planes in $x_1x_2x_3$-space
  \end{block}
\end{frame}

\begin{frame}[label=possibilities3]{Possible situations}

\vspace*{-10pt}

\begin{center}\includegraphics[width=10cm]{planes-2.png}
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[label=solving-3]{Solving linear systems in dimension $3$:}

\vspace*{-8pt}

\begin{block}{By elimination:}

\vspace*{-8pt}

\begin{align*}
    &\begin{matrix}[rrrrr]
        2x &+ \hphantom{2}y & &= \hphantom{-}3 &\\
        4x &- 2y & + 3z&= \hphantom{-}4 & \qquad \alert{-2\times(r_1)}\\
            & \hphantom{-}4y & -2z &=\hphantom{-}0 &
    \end{matrix}
\\
     &\begin{matrix}[rrrrr]
        2x &+ \hphantom{2}y & &= \hphantom{-}3 &\\
           &- 4y & + 3z&= -2        &\\
            & \hphantom{-}4y & -2z &=\hphantom{-}0 &\qquad
                \alert{+ 1\times(r_2)}
    \end{matrix}
\\
     &\begin{matrix}[rrrrr]
        2x &+ \hphantom{2}y & & = \hphantom{-}3 & \\
           &- 4y & + 3z&= -2 & \qquad\alert{-3\times(r_3); \quad /(-4)}\\
            &  & \hphantom{-2}z &=-2 &
    \end{matrix}
\\
     &\begin{matrix}[rrrrr]
        2x &+ \hphantom{2}y & & = \hphantom{-}3 & \qquad\alert{-1\times(r_2); \quad /2} \\
           &\hphantom{- 4}y & &= -1 & \\
            &  & \hphantom{-2}z &=-2 &
    \end{matrix}
\end{align*}
 \alert{Solution:} \ $(2,-1,-2)$
\end{block}


\end{frame}

\section{Gaussian and Gauss--Jordan elimination}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Reduction to an echelon form}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[label=large-n]{How to solve linear systems for large~$n,m$?}

In real-world applications \alert{$m,n>1000$}

\begin{block}{Main questions:}
\begin{enumerate}
  \item Is there any solution to such a linear system?
  \item How many?
  \item How to find all/some special?
\end{enumerate}
\end{block}

\begin{block}{Idea:}
 Transform a system to simpler form without changing the set of solutions
\end{block}

\begin{definition}
\begin{itemize}
  \item A system is called \alert{consistent} if it possesses at least one solution
  \item Two linear systems are called \alert{equivalent} if they possess the same set of solutions
\end{itemize}
\end{definition}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[label=matrix-formulation]{Shorthand matrix notations for linear systems:}

\begin{equation}\label{eq:lin-sys1} \begin{matrix}
    a_{11} {x_1} + a_{12} {x_2} + \cdots + a_{1n}  {x_n} \hspace{-8pt}&= \ b_1\\
    a_{21} {x_1} + a_{22} {x_2} + \cdots + a_{2n}  {x_n} \hspace{-8pt}&= \ b_2\\
    \hdotsfor{2} \\
    a_{m1} {x_1} + a_{m2} {x_2} + \cdots + a_{mn}  {x_n} \hspace{-8pt}&= \,b_m
   \end{matrix}
   \qquad \rightsquigarrow \qquad
   A\bx = \bb
\end{equation}
where
\[
    A = \begin{pmatrix}
      a_{11} & a_{12} & \dots & a_{1n} \\
      a_{21} & a_{22} & \dots & a_{2n}  \\
      \hdotsfor{4} \\
      a_{m1} & a_{m2} & \dots & a_{mn}
    \end{pmatrix}
    \qquad \text{is an $m\times n$ \alert{coefficient matrix}}
\]

\( \bx =
    \left( \!\!\begin{array}{c}
      x_1\\x_2\\ \vdots \\ x_n
    \end{array}\!\!\right) = (x_1, x_2, \dots, x_n)^\top,
    \ \ \bb =
    \left(\!\!\begin{array}{c}
      b_1\\b_2\\ \vdots \\ b_m
    \end{array}\!\!\right) = (b_1, b_2, \dots, b_m)^\top
\)
are the \alert{vector of unknowns} and the (given) \alert{RHS} vector resp.
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[label=augmented-matrix]{Augmented coefficient matrix}
  \begin{block}{}
  Often it is more convenient to combine the matrix notation for the coefficient matrix $A$ and the RHS $\bb$ and to encode system~\eqref{eq:lin-sys1} via the \alert{augmented coefficient matrix}
  \[
    (A\mid\bb) = \begin{pmatrix}[rrcr|r]
      a_{11} & a_{12} & \dots & a_{1n} & b_1 \\
      a_{21} & a_{22} & \dots & a_{2n} & b_2 \\
      \cdots & \cdots & \cdots & \cdots & \vdots   \\
      a_{m1} & a_{m2} & \dots & a_{mn} & b_m
    \end{pmatrix}
  \]
  \end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[label=elem-row]{Elementary row operations that simplify linear systems}
 \begin{itemize}
   \item[1.] Multiply {\color{blue} an equation}/{\color{purple} a row} through by a nonzero constant
   \item[2.] Add a constant times one {\color{blue}equation}/{\color{purple} row} to another
   \item[3.] Interchange two {\color{blue} equations}/{\color{purple}rows}
 \end{itemize}

\begin{definition}
 Matrices $A$ and $B$ are \alert{row equivalent} if $B$ can be obtained from~$A$ via elementary row operations
\end{definition}

\begin{block}{Properties}
\begin{enumerate}
  \item Elementary row operations are reversible
  \item Lead to equivalent systems/augmented matrices
\end{enumerate}
\end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[label=ERO-example]{Example: elementary row operations}

\vspace*{-20pt}
\begin{alignat*}{2}
  \begin{matrix}
    \hphantom{2}x +            2y - \hphantom{-}z  & = \hphantom{-}2 \\
               2x + \hphantom{2}y - \hphantom{-}z  & = \hphantom{-}1 \\
    \hphantom{2}x + \hphantom{2}y - \hphantom{-}z  & = \hphantom{-}0
  \end{matrix}
        & \qquad
  \begin{matrix}
     \\
   \alert{-2\times (r_1)} \\
   \alert{-1\times (r_1)}
  \end{matrix}
        \qquad &
  \begin{pmatrix}[rrr|r]
    1 &  2 & -1 & \hphantom{-}2 \\
    2 & \hphantom{-}1 & -1 & \hphantom{-}1 \\
    1 & \hphantom{-}1 & -1 & \hphantom{-}0
  \end{pmatrix}&
  \\[2pt]
  \begin{matrix}
    \hphantom{2}x +            2y - \hphantom{-}z  & = \hphantom{-}2 \\
    \hphantom{2x} -            3y + \hphantom{-}z  & = -3 \\
    \hphantom{2x} - \hphantom{2}y  \hphantom{--z}  & = -2  \end{matrix}
& \qquad
  \begin{matrix}
     \\
   \alert{(r_2) \leftrightarrow (r_3)} \\
   \alert{(r_2) \leftrightarrow (r_3)}
  \end{matrix}
        \qquad &
  \begin{pmatrix}[rrr|r]
    1 & 2 & -1 & 2 \\
    0 & -3 & 1 & -3 \\
    0 & -1 & 0 & -2
  \end{pmatrix}&
    \\[2pt]
  \begin{matrix}
    \hphantom{2}x +            2y - \hphantom{-}z  & = \hphantom{-}2 \\
    \hphantom{2x}\alert{-}\hphantom{2}y  \hphantom{--z}  & = \alert{-}2 \\
    \hphantom{2x} -            3y + \hphantom{-}z  & = -3   \end{matrix}
& \qquad
  \begin{matrix}[c]
     \\
     \\
   \alert{+3\,\times (r_2)}
  \end{matrix}
        \qquad & \begin{pmatrix}[rrr|r]
    1 &  2 & -1 &  2 \\
    0 &  \alert{-}1 &  0 & \alert{-}2 \\
    0 & -3 &  1 & -3
  \end{pmatrix}&
      \\[2pt]
  \begin{matrix}
    \hphantom{2}x +            2y - \hphantom{-}z  & = \hphantom{-}2 \\
    \hphantom{2x-2}y  \hphantom{--z}  & = \hphantom{-}2 \\
    \hphantom{2x+2y-} \hphantom{-}z  & = \hphantom{-}3   \end{matrix}
& \qquad
  \begin{matrix}[c]
     \alert{-2\times(r_2) + (r_3)}\\
    \\
    \null
  \end{matrix}
        \qquad &
  \begin{pmatrix}[rrr|r]
    1 & \hphantom{-}2 & -1 & \hphantom{-}2 \\
    0 & \hphantom{-}1 & \hphantom{-}0 & \hphantom{-}2 \\
    0 & \hphantom{-}0 & \hphantom{-}1 & \hphantom{-}3
  \end{pmatrix}&
       \\[2pt]
  \begin{matrix}
    \hphantom{2}x             \hphantom{+2y - -z}  & = \hphantom{-}1 \\
    \hphantom{2x-2}y  \hphantom{--z}  & = \hphantom{-}2 \\
    \hphantom{2x+2y-} \hphantom{-}z  & = \hphantom{-}3   \end{matrix}
& \quad
  \begin{matrix}
     \\
    \\
   \null
  \end{matrix}
        \qquad &
  \begin{pmatrix}[rrr|r]
    1 & \hphantom{-}0 & \hphantom{-}0 & \hphantom{-}1 \\
    0 & \hphantom{-}1 & \hphantom{-}0 & \hphantom{-}2 \\
    0 & \hphantom{-}0 & \hphantom{-}1 & \hphantom{-}3
  \end{pmatrix}&
\end{alignat*}
%\textbf{Solution: } $x = 1$, $y=2$, $z=3$
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[label=echelon]{An echelon form}

\vspace*{-5pt}

  \begin{definition}
    A rectangular matrix is in a \alert{row echelon form} if it has the following three properties:
    \begin{enumerate}
      \item All nonzero rows are above any zero row
      \item Each leading entry of a row (i.e., first nonzero entry in that row) is in the column to the right of of the leading entry of the row above it
      \item All entries in a column below a leading entry are zeros
    \end{enumerate}
  \end{definition}

\vspace*{-5pt}

  \begin{example}[$\bullet$ stands for a nonzero number, $\ast$ for any number]
  \[
    \begin{pmatrix}
      \bullet & \ast    & \ast  & \ast  & \ast \\
      0       & \bullet & \ast  & \ast  & \ast \\
      0       &     0   &   0   &   0   & \bullet \\
      0       &     0   &   0   &   0   & 0
    \end{pmatrix},
    \qquad
    \begin{pmatrix}
      0       &   \bullet & \ast  & \ast    & \ast  & \ast\\
      0       &   0     & 0     & \bullet   & \ast  & \ast   \\
      0       &     0   &   0   &   0       & 0     & \bullet\\
      0       &     0   &   0   &   0       & 0     &  \ast
    \end{pmatrix}
  \]
  The first matrix is in echelon form, the second is not unless\dots
  \end{example}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Pivot and free variables}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[label=pivot-free]{Pivot and free variables}

\vspace*{-8pt}

\begin{question}
  Is an echelon form of a matrix unique?
\end{question}

\vspace*{-8pt}

\begin{itemize}
\item
  \alert{No}, because it depends on what elementary row operations and in what order were applied
\item However, the positions of the leading entries are fixed!
\end{itemize}


\vspace*{-8pt}

\begin{definition}
Let $A$ be a matrix of a linear system.
A \alert{pivot column} of $A$ is a column with a leading entry in an echelon form of $A$.
The corresponding variable is called a \alert{pivot variable}.
Otherwise a variable is called \alert{free}.
\end{definition}

\vspace*{-8pt}

\begin{example}[Columns corresponding to free variables are in red ]
  \[
    \begin{pmatrix}%[\color{red}c\color{red}ccc{\color{red}c}]
      \bullet & \ast    & \alert{\ast}  & \alert{\ast}  & \ast \\
      0       & \bullet & \alert{\ast}  & \alert{\ast}  & \ast \\
      0       &     0   &   \alert{0}   &   \alert{0}   & \bullet \\
      0       &     0   &   \alert{0}   &   \alert{0}   & 0
    \end{pmatrix},
    \qquad
    \begin{pmatrix}%[ccccc]
     \alert{0}       &   \bullet & \alert{\ast}  & \ast    & \alert{\ast}  & \ast\\
     \alert{0}       &   0     & \alert{0}     & \bullet   & \alert{\ast}  & \ast   \\
     \alert{0}       &     0   &   \alert{0}   &   0       & \alert{0}     & \bullet\\
     \alert{0}       &     0   &   \alert{0}   &   0       & \alert{0}     &  \ast
    \end{pmatrix}
\]
\end{example}

\end{frame}

\begin{frame}[label=free]{Why free variables are free?}
\[
\begin{pmatrix}[rrrr|r]
      1  &  2   &  -2  &   1   & 0 \\
      0  &  0   &   1  &  -1   & 2
 %     0  &  0   &   0  &   2   & 4
\end{pmatrix}
    \quad
    \iff
    \quad
\begin{matrix}[rrrrr]
    x_1 &+\ 2\alert{x_2}& -\ 2x_3& +\hphantom{2}\alert{x_4} &=0 \\
        &  &  \hphantom{2}x_3 & - \hphantom{2}\alert{x_4} &=2
 %       &      &                   &\ 2x_4 &=4
\end{matrix}
\]

Therefore
\begin{enumerate}
  \item $x_3 = 2 + \alert{x_4}$
  \item $x_1 = - 2 \alert{x_2} + 2x_3-\alert{x_4}
            =  4 - 2 \alert{x_2} + \alert{x_4} $
  \item by introducing \alert{parameters} $\blue{s}$ and $\purple{t}$ via $x_2:=\blue{s}$ and $x_4:= \purple{t}$, we get the following \alert{parametric representation} of general solutions of the system for every values of $\blue{s}$ and $\purple{t}$:
  \begin{align*}
      x_1 & = 4 - 2\blue{s} + \purple{t}\\
      x_2 & = \blue{s} \\
      x_3 & = 2 + \purple{t}\\
      x_4 & = \purple{t}
  \end{align*}
\end{enumerate}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{A reduced echelon form}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[label=reduced-echelon]{A reduced echelon form}

  \vspace*{-10pt}

  \begin{definition}
    A rectangular matrix in an echelon form is in a \alert{reduced row echelon form} if in addition:
    \begin{enumerate}
      \item The leading entry in each nonzero row is~$1$
      \item Each leading~$1$ is the only nonzero element in its column
    \end{enumerate}
  \end{definition}

  \vspace*{-8pt}

  \begin{example}[$\ast$ stands for any number]
  \[
    \begin{pmatrix}
      1     & 0    & \ast  & \ast  & 0 \\
      0       & 1 & \ast  & \ast  & 0 \\
      0       &     0   &   0   &   0   & 1
 %     0       &     0   &   0   &   0   & 0
    \end{pmatrix},
    \qquad
    \begin{pmatrix}
      0       &   1     & \ast  & 0    & \ast  & 0\\
      0       &   0     & 0     & 1   & \ast  & 0  \\
      0       &     0   &   0   &   0       & 0     & 1
 %     0       &     0   &   0   &   0       & 0     &  0
    \end{pmatrix}
  \]
 % These matrices are in reduced echelon form
  \end{example}

  \vspace*{-8pt}

 \begin{block}{}
   \begin{enumerate}
     \item Matrix in echelon form can be transformed to a reduced echelon form using elementary row operations
     \item A reduced echelon form of a matrix is \alert{unique}
     \item If the augmented matrix is in the reduced echelon form, solutions are easy to write in terms of free variables
   \end{enumerate}
 \end{block}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Gaussian and Gauss--Jordan elimination}

Forward substitution $\rightsquigarrow$ an echelon form

\begin{example}[Gaussian elimination $\iff$
substitution]
\[
  \begin{matrix}[rr]
    x +2y\!&= 1 \\
    3x+4y\!&= 1
\end{matrix}
\iff
\begin{matrix}[rr]
    x + 2y &= 1 \\
    3\alert{(1-2y)}+ 4y&= 1
\end{matrix}
  \iff
 \begin{matrix}[rr]
    x + 2y \! &=\hphantom{-} 1 \\
    -2y \! &= -2
\end{matrix}
\]

\vspace*{-10pt}

\[
\begin{pmatrix}[rr|r]
    1 & 2 & 1\\
    3 & 4 & 1
\end{pmatrix}
\sim
\begin{pmatrix}[rr|r]
    1 & 2 & 1\\
    0 & -2 & -2
\end{pmatrix}
\]
\end{example}

Backward substitution $\rightsquigarrow$ reduced echelon form

\begin{example}[Gauss--Jordan elimination $\iff$ back substitution]
  \[
  \begin{matrix}[rr]
    x + 2y \! &=\hphantom{-} 1 \\
    -2y \! &= -2
  \end{matrix}
  \iff
    \begin{matrix}[rr]
    x + 2\cdot\alert{1} &= 1 \\
    \alert{y}&= 1
\end{matrix}
\iff
    \begin{matrix}[rr]
    x \hphantom{+ 23y} &=-1 \\
    y&=\hphantom{-}1
\end{matrix}
  \]

\vspace*{-10pt}

  \[
\begin{pmatrix}[rr|r]
    1 & 2 & 1\\
    0 & -2 & -2
\end{pmatrix}
\quad\sim \quad
\begin{pmatrix}[rr|r]
    1 & 2 & 1\\
    0 & 1 & 1
\end{pmatrix}
\quad\sim \quad
\begin{pmatrix}[rr|r]
    1 & 0 & -1\\
    0 & 1 & \hphantom{-}1
\end{pmatrix}
\]
\end{example}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{Existence and uniqueness of solutions}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Homogeneous and non-homogeneous systems}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[label=homogeneous]{Solution set of homogeneous systems}

\vspace*{-10pt}

\begin{itemize}
  \item A homogeneous system $A \bx = \mathbf{0}$ always has a \alert{trivial solution} $\bx = \mathbf{0}$ (is always consistent)
  \item If $\bx=(x_1,\dots,x_n)^\top$ is a solutions, then for every scalar~$\alert{k}$, $\alert{k}\bx=(\alert{k}x_1,\dots,\alert{k}x_n)^\top$ is a solution as well:\\[-20pt]
      \[  %\begin{multline*}
          a_{i1}(\alert{k}x_1) %+ a_{i2}(\alert{k}x_2)
            + \dots + a_{in}(\alert{k}x_n)
          = \alert{k}(a_{i1}x_1 %+ a_{i2}x_2
            + \dots + a_{in}x_n) = 0
      \]  %\end{multline*}
  \item If $\bx = (x_1,\dots,x_n)^\top$ and $\by = (y_1,\dots,y_n)^\top$   are solutions, then so is $\bx+\by = (x_1 + y_1 , \dots,x_n + y_n)^\top$:\\[-20pt]
    \begin{multline*}
          a_{i1}(x_1 + y_1) +  \dots + a_{in}(x_n+y_n)\\
          = (a_{i1}x_1 +  \dots + a_{in}x_n) +
           (a_{i1}y_1 +  \dots + a_{in}y_n) = 0
    \end{multline*}
  \item Thus the \alert{solution set} of a homogeneous linear system is a \uwave{linear space}
\end{itemize}
\begin{theorem}[Solutions to a homogeneous system]
  A homogeneous system $A \bx = \mathbf{0}$ may have one solution (the {trivial solution} $\bx=\mathbf{0}$) or infinitely many solutions; moreover, its solution set is linear.
\end{theorem}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[label=nonhomogeneous]{Solution set of non-homogeneous systems}

\vspace*{-10pt}

\begin{itemize}
  \item A non-homogeneous system $A \bx = \mathbf{b}$ need not be consistent (may not have any solutions)
  \item If $\bx = (x_1,\dots,x_n)^\top$ and $\by = (y_1,\dots,y_n)^\top$   are solutions, then  $\bx-\by = (x_1 - y_1 , \dots,x_n - y_n)^\top$ solves the homogeneous system $A\bx = \mathbf{0}$:\\[-20pt]
    \begin{multline*}
          a_{i1}(x_1 - y_1) +  \dots + a_{in}(x_n-y_n)\\
          = (a_{i1}x_1 +  \dots + a_{in}x_n) -
           (a_{i1}y_1 +  \dots + a_{in}y_n) \\= b_i - b_i = 0
    \end{multline*}\\[-25pt]
  \item The \alert{solution set} of a non-homogeneous linear system is an \uwave{affine set} (shifted linear set)
\end{itemize}

\begin{theorem}[Solutions to a non-homogeneous system]
  A non-homogeneous system $A \bx = \mathbf{b}$ may have \alert{no} solutions, \alert{one} solution,  or \alert{infinitely many} solutions. Any solution has the form $\bx = \bx_{\mathrm{par}} + \bx_{\mathrm{hom}}$, where $\bx_{\mathrm{par}}$ is a particular solution, and $\bx_{\mathrm{hom}}$ is any solution to a homogeneous system $A\bx = \mathbf{0}$
\end{theorem}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Existence and uniqueness of solutions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[label=existence]{Existence of solutions}
  \begin{itemize}
    \item A homogeneous system $A\bx = \mathbf{0}$ is \alert{always} consistent
    \item A non-homogeneous system $A\bx = \bb$ is consistent\\[5pt]
    $\iff$ \begin{minipage}{8cm}
        an echelon form of its augmented matrix $(A \,| \,\bb)$ has no row $(0\, \dots\, 0 \,| \,\bullet)$ with a non-zero $\bullet$
        \end{minipage}
    \item A system $A\bx = \bb$ is consistent for \alert{every} $\bb$ \\
    $\iff$ an echelon form of~$A$ has no zero rows\\ $\iff$ $A$ has a pivot position in every its row
    \item For every $A$, the system $A\bx = \bb$ is consistent for \alert{some} choice of $\bb$.
  \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[label=uniqueness]{Uniqueness of solutions}

  \begin{itemize}
   \item A homogeneous system $A\bx = \mathbf{0}$ has a unique solution \\
   $\iff$ there is \alert{no} free variables
      \vspace{2pt}
   \item A non-homogeneous system $A\bx = \bb$ has a unique solution\\[5pt]
   $\iff$ \begin{minipage}{9cm}
      \alert{no} rows  $(0\, \dots\, 0 \,| \,\bullet)$ in echelon form of~$(A \,|\,\bb)$ \purple{and} \\
      \alert{no} free variables
      \end{minipage}
      \vspace{2pt}
   \item A system $A\bx =\bb$ has a unique solution for \alert{every} $\bb$\\[5pt]
    $\iff$ \begin{minipage}{9cm}
      \alert{no} zero rows in an echelon form of~$A$  \purple{and} \\
      \alert{no} free variables
      \end{minipage}\\[5pt]
    $\implies$ \begin{minipage}{9cm}
      $A$ must be a \alert{square matrix} ($m=n$)
    \end{minipage}
  \end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Nonsingular matrices. Rank of a matrix}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[label=singular]{Nonsingular matrices}

 \vspace*{-10pt}

 \begin{definition}
   A coefficient matrix~$A$ is called \alert{nonsingular} if the linear system $A\bx = \bb$ has a unique solution for \uwave{\sl every} choice of $\bb$.
 \end{definition}

 \vspace*{-9pt}

 \begin{theorem}
  An $m\times n$ matrix $A$ is nonsingular if and only if $m=n$ and $A$ has $m$ pivot columns
 \end{theorem}

 \vspace*{-9pt}

 \begin{proof}[Proof:]
  \begin{itemize}
    \item should be no free variables (otherwise nonuniqueness)
    \item an echelon form of~$A$ should contain no zero rows (otherwise nonexistence)
  \end{itemize}
      \vspace*{-20pt}
 \end{proof}

 \vspace*{-9pt}

\begin{example}
 \vspace*{-10pt}
\[
 \begin{pmatrix}[rrr]
    1 &  2 & a \\ 3 & b & 0 \\ c & 0 & 0
 \end{pmatrix}
 \stackrel{c\ne0}{\sim}
 \begin{pmatrix}[rrr]
    1 &  2 & a \\ 0 & b & 0 \\ 1 & 0 & 0
 \end{pmatrix}
 \stackrel{b\ne0}{\sim}
 \begin{pmatrix}[rrr]
    1 &  2 & a \\ 0 & 1 & 0 \\ 1 & 0 & 0
 \end{pmatrix}
 \sim
 \begin{pmatrix}[rrr]
    1 &  2 & a \\ 0 & 1 & 0 \\ 0 & 0 & a
 \end{pmatrix}
 \]

 \vspace*{-13pt}

 Thus $A$ is nonsingular $\iff$ $abc\ne0$
 \end{example}

\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[label=rank]{Rank of a matrix}

  \begin{definition}
    The number of nonzero rows in an echelon form of a matrix~$A$ is called its \alert{rank}
    and denoted $\rank A$.
  \end{definition}

 \begin{theorem}[Some properties of the rank]
  Assume that $A$ is the $m\times n$ coefficient matrix of a linear system and $\hat A$ is the corresponding
  augmented matrix. Then
  \begin{enumerate}
   \item  $\rank A \le \min\{m,n\}$ and $\rank A \le \rank \hat A$
   \item a solution of $A\bx = \bb$ exists $\iff$ $\rank A = \rank \hat A$
   \item $A\bx = \bb$ is consistent for every $\bb$ $\iff$ $\rank A = m$
   \item $A\bx = \bb$ has at most one solution for every $\bb$ $\iff$ $\rank A =n$
   \item $A$ is nonsingular $\iff$ $\rank A = m = n$.
  \end{enumerate}
 \end{theorem}

\end{frame}

\end{document}




